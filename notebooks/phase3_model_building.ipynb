{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Phase 3: Model Building\n",
    "# Xây dựng Mô hình\n",
    "\n",
    "## Mục tiêu / Objectives:\n",
    "1. Build 5+ classification models\n",
    "2. Build 5+ regression models\n",
    "3. Define hyperparameter grids\n",
    "4. Prepare for training and evaluation\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import libraries\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import pickle\n",
    "import warnings\n",
    "import sys\n",
    "import os\n",
    "\n",
    "# Scikit-learn\n",
    "from sklearn.linear_model import LogisticRegression, LinearRegression\n",
    "from sklearn.ensemble import RandomForestClassifier, RandomForestRegressor\n",
    "from sklearn.ensemble import GradientBoostingRegressor\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.model_selection import GridSearchCV, cross_val_score\n",
    "from sklearn.metrics import accuracy_score, classification_report, confusion_matrix\n",
    "from sklearn.metrics import mean_squared_error, r2_score, mean_absolute_error\n",
    "\n",
    "# XGBoost\n",
    "import xgboost as xgb\n",
    "\n",
    "# TensorFlow/Keras\n",
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "from tensorflow.keras import layers\n",
    "\n",
    "# Add src to path\n",
    "sys.path.append('../src')\n",
    "from data_split import load_split_data, split_features_target\n",
    "\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "print('Libraries imported successfully!')\n",
    "print(f'TensorFlow version: {tf.__version__}')\n",
    "print(f'XGBoost version: {xgb.__version__}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Load Train and Test Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load split data\n",
    "train_df, test_df, encoders = load_split_data('../data/processed')\n",
    "\n",
    "print(f'Train set: {train_df.shape}')\n",
    "print(f'Test set: {test_df.shape}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Classification Models\n",
    "\n",
    "### 2.1 Logistic Regression (Baseline)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO: Implement Logistic Regression\n",
    "# Define hyperparameter grid\n",
    "lr_params = {\n",
    "    'C': [0.01, 0.1, 1, 10, 100],\n",
    "    'penalty': ['l1', 'l2'],\n",
    "    'solver': ['liblinear', 'saga']\n",
    "}\n",
    "\n",
    "print('Logistic Regression model configured')\n",
    "print(f'Hyperparameter grid: {lr_params}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.2 Random Forest Classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO: Implement Random Forest Classifier\n",
    "rf_clf_params = {\n",
    "    'n_estimators': [100, 200, 300],\n",
    "    'max_depth': [10, 20, 30, None],\n",
    "    'min_samples_split': [2, 5, 10],\n",
    "    'min_samples_leaf': [1, 2, 4]\n",
    "}\n",
    "\n",
    "print('Random Forest Classifier configured')\n",
    "print(f'Hyperparameter grid: {rf_clf_params}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.3 XGBoost Classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO: Implement XGBoost Classifier\n",
    "xgb_clf_params = {\n",
    "    'n_estimators': [100, 200, 300],\n",
    "    'max_depth': [3, 5, 7, 9],\n",
    "    'learning_rate': [0.01, 0.1, 0.3],\n",
    "    'subsample': [0.7, 0.8, 0.9, 1.0]\n",
    "}\n",
    "\n",
    "print('XGBoost Classifier configured')\n",
    "print(f'Hyperparameter grid: {xgb_clf_params}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.4 Support Vector Machine"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO: Implement SVM\n",
    "svm_params = {\n",
    "    'C': [0.1, 1, 10, 100],\n",
    "    'kernel': ['rbf', 'poly', 'sigmoid'],\n",
    "    'gamma': ['scale', 'auto']\n",
    "}\n",
    "\n",
    "print('SVM configured')\n",
    "print(f'Hyperparameter grid: {svm_params}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.5 Neural Network Classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO: Implement Neural Network\n",
    "def build_classification_nn(input_dim, num_classes):\n",
    "    model = keras.Sequential([\n",
    "        layers.Dense(128, activation='relu', input_dim=input_dim),\n",
    "        layers.Dropout(0.3),\n",
    "        layers.Dense(64, activation='relu'),\n",
    "        layers.Dropout(0.2),\n",
    "        layers.Dense(32, activation='relu'),\n",
    "        layers.Dense(num_classes, activation='softmax')\n",
    "    ])\n",
    "    \n",
    "    model.compile(\n",
    "        optimizer='adam',\n",
    "        loss='categorical_crossentropy',\n",
    "        metrics=['accuracy']\n",
    "    )\n",
    "    \n",
    "    return model\n",
    "\n",
    "print('Neural Network Classifier architecture defined')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Regression Models\n",
    "\n",
    "### 3.1 Linear Regression (Baseline)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO: Implement Linear Regression\n",
    "print('Linear Regression model configured')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.2 Random Forest Regressor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO: Implement Random Forest Regressor\n",
    "rf_reg_params = {\n",
    "    'n_estimators': [100, 200, 300],\n",
    "    'max_depth': [10, 20, 30, None],\n",
    "    'min_samples_split': [2, 5, 10],\n",
    "    'min_samples_leaf': [1, 2, 4]\n",
    "}\n",
    "\n",
    "print('Random Forest Regressor configured')\n",
    "print(f'Hyperparameter grid: {rf_reg_params}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.3 XGBoost Regressor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO: Implement XGBoost Regressor\n",
    "xgb_reg_params = {\n",
    "    'n_estimators': [100, 200, 300],\n",
    "    'max_depth': [3, 5, 7],\n",
    "    'learning_rate': [0.01, 0.1, 0.3],\n",
    "    'subsample': [0.7, 0.8, 0.9]\n",
    "}\n",
    "\n",
    "print('XGBoost Regressor configured')\n",
    "print(f'Hyperparameter grid: {xgb_reg_params}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.4 Gradient Boosting Regressor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO: Implement Gradient Boosting\n",
    "gb_params = {\n",
    "    'n_estimators': [100, 200, 300],\n",
    "    'max_depth': [3, 5, 7],\n",
    "    'learning_rate': [0.01, 0.1, 0.2],\n",
    "    'subsample': [0.7, 0.8, 0.9]\n",
    "}\n",
    "\n",
    "print('Gradient Boosting Regressor configured')\n",
    "print(f'Hyperparameter grid: {gb_params}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.5 Neural Network Regressor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO: Implement Neural Network Regressor\n",
    "def build_regression_nn(input_dim):\n",
    "    model = keras.Sequential([\n",
    "        layers.Dense(128, activation='relu', input_dim=input_dim),\n",
    "        layers.Dropout(0.3),\n",
    "        layers.Dense(64, activation='relu'),\n",
    "        layers.Dropout(0.2),\n",
    "        layers.Dense(32, activation='relu'),\n",
    "        layers.Dense(1, activation='linear')\n",
    "    ])\n",
    "    \n",
    "    model.compile(\n",
    "        optimizer='adam',\n",
    "        loss='mse',\n",
    "        metrics=['mae']\n",
    "    )\n",
    "    \n",
    "    return model\n",
    "\n",
    "print('Neural Network Regressor architecture defined')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Summary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print('='*80)\n",
    "print('MODEL BUILDING SUMMARY')\n",
    "print('='*80)\n",
    "\n",
    "print('\\nClassification Models:')\n",
    "print('1. Logistic Regression (Baseline)')\n",
    "print('2. Random Forest Classifier')\n",
    "print('3. XGBoost Classifier')\n",
    "print('4. Support Vector Machine')\n",
    "print('5. Neural Network Classifier')\n",
    "\n",
    "print('\\nRegression Models:')\n",
    "print('1. Linear Regression (Baseline)')\n",
    "print('2. Random Forest Regressor')\n",
    "print('3. XGBoost Regressor')\n",
    "print('4. Gradient Boosting Regressor')\n",
    "print('5. Neural Network Regressor')\n",
    "\n",
    "print('\\n✓ MODEL BUILDING PHASE COMPLETE!')\n",
    "print('Next: Proceed to Phase 4 - Training & Evaluation')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
